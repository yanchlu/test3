
# 项目主题：自然语言问答

为完成该项目，我们组总共进行了三次尝试。

第一次是根据Google AI提供的40G数据和相应的代码，尝试去调试自然语言问答模型。

由于数据集太大，训练速度过慢，且训练出的模型出现BUG，未能捕获问题标签[Q]，因此不得不放弃。

第二次尝试改用相对较小的CoQA数据集，使用BERT+AnswerVerification进行训练。

但在训练的时候出现了OOM的问题，只能改小batch_size，导致训练效果并不理想。

第三次将模型换成BERT+SDNet+CoQA, 取得了f1 = 77 的训练成绩。

# 模型的改进方面

代码改进的地方还有很多，比如解决第二次尝试中的OOM问题使它能适应更大的batch_size。

又或是将第三次尝试中的RNN部分用Transformer代替。还可以针对模型比较薄弱的特定类型问题进行训练。因为CoQA数据集中no answer的训练偏少。